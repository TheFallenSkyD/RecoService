{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debc4873",
   "metadata": {
    "id": "debc4873",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:26.752014400Z",
     "start_time": "2023-12-13T12:44:26.694014900Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0EIkfyw23T8C",
   "metadata": {
    "id": "0EIkfyw23T8C"
   },
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "843b139a",
   "metadata": {
    "id": "843b139a",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.526102400Z",
     "start_time": "2023-12-13T12:44:26.709015200Z"
    }
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"../datasets/users.csv\")\n",
    "items_df = pd.read_csv(\"../datasets/items.csv\")\n",
    "interactions_df = pd.read_csv(\"../datasets/interactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fbac8ce",
   "metadata": {
    "id": "0fbac8ce",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.664141700Z",
     "start_time": "2023-12-13T12:44:28.619637200Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df[\"last_watch_dt\"] < \"2021-04-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fNDeyNFW5acR",
   "metadata": {
    "id": "fNDeyNFW5acR"
   },
   "source": [
    "Оставляем только тех пользователей, у которых больше 5 просмотров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78342a0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78342a0b",
    "outputId": "6c5305a5-df7b-4ec2-b432-4caff11179c3",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.738142400Z",
     "start_time": "2023-12-13T12:44:28.665141600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 86614\n",
      "# users with at least 5 interactions: 14563\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df.groupby([\"user_id\", \"item_id\"]).size().groupby(\"user_id\").size()\n",
    ")\n",
    "print(\"# users: %d\" % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[\n",
    "    users_interactions_count_df >= 5\n",
    "].reset_index()[[\"user_id\"]]\n",
    "print(\"# users with at least 5 interactions: %d\" % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bd0d31d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bd0d31d",
    "outputId": "4e3ff185-9575-433a-926b-464251e4f3ed",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.779142900Z",
     "start_time": "2023-12-13T12:44:28.738142400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 263874\n",
      "# of interactions from users with at least 5 interactions: 142670\n"
     ]
    }
   ],
   "source": [
    "print(\"# of interactions: %d\" % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(\n",
    "    users_with_enough_interactions_df, how=\"right\", left_on=\"user_id\", right_on=\"user_id\"\n",
    ")\n",
    "print(\n",
    "    \"# of interactions from users with at least 5 interactions: %d\"\n",
    "    % len(interactions_from_selected_users_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df43577",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "2df43577",
    "outputId": "26d2d48b-53f6-4ca6-c59a-20d8baf4d681",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.827143Z",
     "start_time": "2023-12-13T12:44:28.767141700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 142670\n"
     ]
    },
    {
     "data": {
      "text/plain": "   user_id  item_id  watched_pct\n0       21      849     6.375039\n1       21     4345     6.658211\n2       21    10283     6.658211\n3       21    12261     6.658211\n4       21    15997     6.658211\n5       32      952     6.044394\n6       32     4382     4.954196\n7       32     4807     6.658211\n8       32    10436     6.658211\n9       32    12132     6.658211",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>watched_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>849</td>\n      <td>6.375039</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>4345</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>10283</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>12261</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21</td>\n      <td>15997</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32</td>\n      <td>952</td>\n      <td>6.044394</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>32</td>\n      <td>4382</td>\n      <td>4.954196</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>32</td>\n      <td>4807</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>32</td>\n      <td>10436</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>32</td>\n      <td>12132</td>\n      <td>6.658211</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1 + x, 2)\n",
    "\n",
    "\n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df.groupby([\"user_id\", \"item_id\"])[\"watched_pct\"]\n",
    "    .sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"# of unique user/item interactions: %d\" % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-C-7LfrG201j",
   "metadata": {
    "id": "-C-7LfrG201j"
   },
   "source": [
    "## TRAIN/TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "039e1442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "039e1442",
    "outputId": "b32b8adc-1a17-4d7b-a672-ef8c91ac937a",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.908771600Z",
     "start_time": "2023-12-13T12:44:28.829142500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 114136\n",
      "# interactions on Test set: 28534\n"
     ]
    }
   ],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(\n",
    "    interactions_full_df, stratify=interactions_full_df[\"user_id\"], test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(\"# interactions on Train set: %d\" % len(interactions_train_df))\n",
    "print(\"# interactions on Test set: %d\" % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b38dea2",
   "metadata": {
    "id": "0b38dea2",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.946771700Z",
     "start_time": "2023-12-13T12:44:28.903771700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index(\"user_id\")\n",
    "interactions_train_indexed_df = interactions_train_df.set_index(\"user_id\")\n",
    "interactions_test_indexed_df = interactions_test_df.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbb9a04d",
   "metadata": {
    "id": "bbb9a04d",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.961773300Z",
     "start_time": "2023-12-13T12:44:28.918773Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id][\"item_id\"]\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H962QOt626R-",
   "metadata": {
    "id": "H962QOt626R-"
   },
   "source": [
    "## MODEL LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_VZdPA3g3fq0",
   "metadata": {
    "id": "_VZdPA3g3fq0"
   },
   "source": [
    "## Класс для оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03042d4a",
   "metadata": {
    "id": "03042d4a",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.961773300Z",
     "start_time": "2023-12-13T12:44:28.936771700Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(interactions_full_df[\"item_id\"])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        # Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset[\"item_id\"]) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset[\"item_id\"])\n",
    "        else:\n",
    "            person_interacted_items_testset = {int(interacted_values_testset[\"item_id\"])}\n",
    "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
    "\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(\n",
    "            person_id,\n",
    "            items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df),\n",
    "            topn=10000000000,\n",
    "        )\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            # Getting a random sample (100) items the user has not interacted\n",
    "            # (to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(\n",
    "                person_id,\n",
    "                sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS,\n",
    "                seed=item_id % (2**32),\n",
    "            )\n",
    "\n",
    "            # Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df[\"item_id\"].isin(items_to_filter_recs)]\n",
    "            valid_recs = valid_recs_df[\"item_id\"].values\n",
    "            # Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items,\n",
    "        # when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {\n",
    "            \"hits@5_count\": hits_at_5_count,\n",
    "            \"hits@10_count\": hits_at_10_count,\n",
    "            \"interacted_count\": interacted_items_count_testset,\n",
    "            \"recall@5\": recall_at_5,\n",
    "            \"recall@10\": recall_at_10,\n",
    "        }\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        # print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(\n",
    "            tqdm(list(interactions_test_indexed_df.index.unique().values))\n",
    "        ):\n",
    "            # if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
    "            person_metrics[\"user_id\"] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print(\"%d users processed\" % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics).sort_values(\n",
    "            \"interacted_count\", ascending=False\n",
    "        )\n",
    "\n",
    "        global_recall_at_5 = detailed_results_df[\"hits@5_count\"].sum() / float(\n",
    "            detailed_results_df[\"interacted_count\"].sum()\n",
    "        )\n",
    "        global_recall_at_10 = detailed_results_df[\"hits@10_count\"].sum() / float(\n",
    "            detailed_results_df[\"interacted_count\"].sum()\n",
    "        )\n",
    "\n",
    "        global_metrics = {\n",
    "            \"modelName\": model.get_model_name(),\n",
    "            \"recall@5\": global_recall_at_5,\n",
    "            \"recall@10\": global_recall_at_10,\n",
    "        }\n",
    "        return global_metrics, detailed_results_df\n",
    "\n",
    "\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cS6115Lb3ndt",
   "metadata": {
    "id": "cS6115Lb3ndt"
   },
   "source": [
    "## Преобразование данных в матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b47f52ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b47f52ce",
    "outputId": "78ff3f41-622b-4b7e-8959-9e9ee1337b1c",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:28.964772500Z",
     "start_time": "2023-12-13T12:44:28.948772900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\AppData\\Local\\Temp\\ipykernel_42044\\207808043.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n"
     ]
    }
   ],
   "source": [
    "total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n",
    "total_df[\"user_id\"], users_keys = total_df.user_id.factorize()\n",
    "total_df[\"item_id\"], items_keys = total_df.item_id.factorize()\n",
    "\n",
    "train_encoded = total_df.iloc[: len(interactions_train_df)].values\n",
    "test_encoded = total_df.iloc[len(interactions_train_df) :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27e538cd",
   "metadata": {
    "id": "27e538cd",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:29.112773100Z",
     "start_time": "2023-12-13T12:44:28.964772500Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "shape = [int(total_df[\"user_id\"].max() + 1), int(total_df[\"item_id\"].max() + 1)]\n",
    "X_train = csr_matrix(\n",
    "    (train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape\n",
    ").toarray()\n",
    "X_test = csr_matrix(\n",
    "    (test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape\n",
    ").toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WGCHuMej3yo7",
   "metadata": {
    "id": "WGCHuMej3yo7"
   },
   "source": [
    "## Создание датасета и data loader'ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89cc28b3",
   "metadata": {
    "id": "89cc28b3",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:29.128771900Z",
     "start_time": "2023-12-13T12:44:29.113772700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
    "# for a given idx. This class must also have a length atribute\n",
    "class UserOrientedDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        super().__init__()  # to initialize the parent class\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self):  # We use __func__ for implementing in-built python functions\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9039ffb8",
   "metadata": {
    "id": "9039ffb8",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:29.171812400Z",
     "start_time": "2023-12-13T12:44:29.130772300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "SEED = 42  # random seed for reproducibility\n",
    "LR = 1e-3  # learning rate, controls the speed of the training\n",
    "WEIGHT_DECAY = 0.01  # lambda for L2 reg. ()\n",
    "NUM_EPOCHS = 200  # num training epochs (how many times each instance will be processed)\n",
    "GAMMA = 0.9995  # learning rate scheduler parameter\n",
    "BATCH_SIZE = 3000  # training batch size\n",
    "EVAL_BATCH_SIZE = 3000  # evaluation batch size.\n",
    "DEVICE = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  #'cuda' # device to make the calculations on\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27054192",
   "metadata": {
    "id": "27054192",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:29.671338500Z",
     "start_time": "2023-12-13T12:44:29.144772600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
    "train_dl = DataLoader(UserOrientedDataset(X_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dl = DataLoader(UserOrientedDataset(X_test), batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dls = {\"train\": train_dl, \"test\": test_dl}\n",
    "\n",
    "## Модель\n",
    "# добавила линейных слоев в архитектуру\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features=8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(in_and_out_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, in_and_out_features),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x\n",
    "    ):  # In the forward function, you define how your model runs, from input to output\n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c95f9af",
   "metadata": {
    "id": "2c95f9af",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:44:29.881885300Z",
     "start_time": "2023-12-13T12:44:29.671338500Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)  # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "model = Model()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Initialize GD method, which will update the weights of the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "\n",
    "def rmse_for_sparse(x_pred, x_true):\n",
    "    mask = x_true > 0\n",
    "    sq_diff = (x_pred * mask - x_true) ** 2\n",
    "    mse = sq_diff.sum() / mask.sum()\n",
    "    return mse ** (1 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G41ZGkpL36pY",
   "metadata": {
    "id": "G41ZGkpL36pY"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9cdaf94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "e9cdaf94",
    "outputId": "37af648a-ed8b-4f98-db46-ae51da9bd113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Epoch  Train RMSE  Test RMSE\n0        0    2.328319   2.310662\n1        1    2.295296   2.262220\n2        2    2.161467   2.118939\n3        3    1.928263   1.951626\n4        4    1.723131   1.962615\n..     ...         ...        ...\n195    195    0.701505   1.445914\n196    196    0.699436   1.446174\n197    197    0.700978   1.445047\n198    198    0.697975   1.447076\n199    199    0.696498   1.446473\n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch</th>\n      <th>Train RMSE</th>\n      <th>Test RMSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2.328319</td>\n      <td>2.310662</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.295296</td>\n      <td>2.262220</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2.161467</td>\n      <td>2.118939</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.928263</td>\n      <td>1.951626</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.723131</td>\n      <td>1.962615</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>195</td>\n      <td>0.701505</td>\n      <td>1.445914</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>196</td>\n      <td>0.699436</td>\n      <td>1.446174</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>197</td>\n      <td>0.700978</td>\n      <td>1.445047</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>198</td>\n      <td>0.697975</td>\n      <td>1.447076</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>199</td>\n      <td>0.696498</td>\n      <td>1.446473</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in [\"train\", \"test\"]:\n",
    "        with torch.set_grad_enabled(\n",
    "            stage == \"train\"\n",
    "        ):  # Whether to start building a graph for a backward pass\n",
    "            if stage == \"train\":\n",
    "                model.train()  # Enable some \"special\" layers (will speak about later)\n",
    "            else:\n",
    "                model.eval()  # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "            loss_at_stage = 0\n",
    "            for batch in dls[stage]:\n",
    "                batch = batch.to(DEVICE)\n",
    "                x_pred = model(batch)  # forward pass: model(x_batch) -> calls forward()\n",
    "                loss = rmse_for_sparse(x_pred, batch)  # ¡Important! y_pred is always the first arg\n",
    "                if stage == \"train\":\n",
    "                    loss.backward()  # Calculate the gradients of all the parameters wrt loss\n",
    "                    optimizer.step()  # Update the parameters\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()  # Zero the saved gradient\n",
    "                loss_at_stage += loss.item() * len(batch)\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1 / 2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "\n",
    "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 5:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i5fHcQW54Aqj",
   "metadata": {
    "id": "i5fHcQW54Aqj"
   },
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9bf9546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9bf9546",
    "outputId": "2bbb132d-a66d-41b5-9e58-0b208db673ae",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:24.603057500Z",
     "start_time": "2023-12-13T12:49:24.127711100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 6.8207,  6.8692,  6.3129,  ...,  0.8217,  0.5914, -1.5296],\n        [ 1.3772,  5.1104,  1.1528,  ..., -0.2331,  0.0822, -0.4884],\n        [ 6.4950,  6.5563,  0.6818,  ..., -0.4533,  0.3825,  0.0893],\n        ...,\n        [ 1.7683,  5.5015,  1.2825,  ..., -0.2308,  0.0294, -0.5161],\n        [ 4.9535,  6.3394,  0.6270,  ..., -0.5533,  0.0758, -0.3606],\n        [ 7.1879,  6.2458,  2.2184,  ...,  0.2624, -0.1214,  0.4400]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(torch.Tensor(X_test).to(DEVICE)))\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bca32fb",
   "metadata": {
    "id": "3bca32fb",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:24.622058300Z",
     "start_time": "2023-12-13T12:49:24.594057800Z"
    }
   },
   "outputs": [],
   "source": [
    "class AERecommender:\n",
    "    MODEL_NAME = \"Autoencoder\"\n",
    "\n",
    "    def __init__(self, X_preds, X_train_and_val, X_test):\n",
    "        self.X_preds = X_preds.cpu().detach().numpy()\n",
    "        self.X_train_and_val = X_train_and_val\n",
    "        self.X_test = X_test\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "\n",
    "    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n",
    "        user_preds = self.X_preds[user_id][items_to_select_idx]\n",
    "        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        return items_idx\n",
    "\n",
    "    def evaluate(self, size=100):\n",
    "        X_total = self.X_train_and_val + self.X_test\n",
    "\n",
    "        true_5 = []\n",
    "        true_10 = []\n",
    "\n",
    "        for user_id in range(len(X_test)):\n",
    "            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n",
    "            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n",
    "            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n",
    "\n",
    "            for non_zero_idx in non_zero:\n",
    "                random_non_interacted_100_items = np.random.choice(\n",
    "                    select_from, size=20, replace=False\n",
    "                )\n",
    "                preds = self.recommend_items(\n",
    "                    user_id, np.append(random_non_interacted_100_items, non_zero_idx), topn=10\n",
    "                )\n",
    "                true_5.append(non_zero_idx in preds[:5])\n",
    "                true_10.append(non_zero_idx in preds)\n",
    "\n",
    "        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n",
    "\n",
    "\n",
    "ae_recommender_model = AERecommender(X_pred, X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5WyiXNnzYvzF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WyiXNnzYvzF",
    "outputId": "7131da7f-7387-4496-f9dd-db723b3c2172",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:46.572845100Z",
     "start_time": "2023-12-13T12:49:24.609057600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'recall@5': 0.260904755868041, 'recall@10': 0.5344086126361571}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_global_metrics = ae_recommender_model.evaluate()\n",
    "ae_global_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kR_6EdG-4ILn",
   "metadata": {
    "id": "kR_6EdG-4ILn"
   },
   "source": [
    "# Получение предсказаний для сервиса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "HMCYu8SHowSq",
   "metadata": {
    "id": "HMCYu8SHowSq",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:46.618845600Z",
     "start_time": "2023-12-13T12:49:46.572845100Z"
    }
   },
   "outputs": [],
   "source": [
    "full_encoded = total_df.values\n",
    "shape = [int(total_df[\"user_id\"].max() + 1), int(total_df[\"item_id\"].max() + 1)]\n",
    "X = csr_matrix(\n",
    "    (full_encoded[:, 2], (full_encoded[:, 0], full_encoded[:, 1])), shape=shape\n",
    ").toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d846334",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d846334",
    "outputId": "a820c5c9-09db-453d-96d1-7a3abd74f6bd",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:46.872888100Z",
     "start_time": "2023-12-13T12:49:46.617845100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 6.8321e+00,  7.1502e+00,  5.2008e+00,  ...,  8.3642e-01,\n          1.6031e-02, -1.5003e+00],\n        [ 7.4325e+00,  6.3124e+00,  1.3471e+00,  ...,  3.1435e-01,\n         -1.2993e-01,  4.4573e-01],\n        [ 7.5494e+00,  7.3452e+00,  6.7141e+00,  ...,  4.4832e-01,\n         -4.3390e-01,  1.5213e-01],\n        ...,\n        [ 3.5051e+00,  5.5092e+00,  5.9176e-01,  ..., -5.7087e-01,\n          4.6256e-02, -4.6484e-01],\n        [ 6.4488e+00,  7.4217e+00,  4.8233e+00,  ...,  7.8619e-03,\n         -3.4649e-01, -1.5642e-01],\n        [ 6.0897e+00,  6.7751e+00,  4.0877e+00,  ..., -2.3706e-02,\n         -2.4763e-01,  8.9237e-04]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(torch.Tensor(X).to(DEVICE)))\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fxCKNXMJprEw",
   "metadata": {
    "id": "fxCKNXMJprEw",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:46.916888300Z",
     "start_time": "2023-12-13T12:49:46.873888500Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommend_to_user(user_id, topn=10):\n",
    "    all_nonzero = np.argwhere(X[user_id] > 0).ravel()\n",
    "    select_from = np.setdiff1d(np.arange(X.shape[1]), all_nonzero)\n",
    "    random_non_interacted_100_items = np.random.choice(select_from, size=20, replace=False)\n",
    "    user_preds = X_pred[user_id][random_non_interacted_100_items]\n",
    "    items_idx = random_non_interacted_100_items[np.argsort(-user_preds)[:topn]]\n",
    "    return items_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "od3kyhhemih7",
   "metadata": {
    "id": "od3kyhhemih7",
    "ExecuteTime": {
     "end_time": "2023-12-13T12:49:50.840667200Z",
     "start_time": "2023-12-13T12:49:46.887888400Z"
    }
   },
   "outputs": [],
   "source": [
    "recos = {}\n",
    "users = interactions_full_indexed_df.index.unique().tolist()\n",
    "for i, user_id in enumerate(users):\n",
    "    recos_for_user = recommend_to_user(i)\n",
    "    recos.update({user_id: recos_for_user.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/recsys/AE_recos.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/content/drive/MyDrive/recsys/AE_recos.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m jf:\n\u001B[0;32m      2\u001B[0m     json\u001B[38;5;241m.\u001B[39mdump(recos, jf)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recoservice-Q0zB1aiD-py3.10\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[1;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/recsys/AE_recos.json'"
     ]
    }
   ],
   "source": [
    "with open(\"autoencoder.json\", \"w\") as f:\n",
    "    json.dump(recos, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "vQJwdSzamU8U"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
